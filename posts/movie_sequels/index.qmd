---
title: How Successful Are Movie Sequels?
date: '2024-03-29'
subtitle: Find an overview of the movie sequel landscape looking at the past 100 years of film.
categories: [Python, Data Journalism]
image: https://cdn.pixabay.com/photo/2023/01/12/04/36/cinema-7713265_1280.png
title-block-banner: false
draft: false
toc: true
freeze: true
toc-depth: 5
toc-title: Page Contents
code-links:
  - text: Python Script
    icon: code-slash
    href: /files/sequel_analysis.py
  - text: Data
    icon: database
    href: /files/cleaned_data_w_rev.xlsx
---

<center><img src="https://cdn.pixabay.com/photo/2023/01/12/04/36/cinema-7713265_1280.png" width="350" height="350" /></center> 

## Introduction

I've wanted to do this post for a while now. When I was younger, it seemed movies were more of a one-off thing. Now, it feels like almost every movie has a sequel and sometimes many more. Lets look at some data to see what's going on here. For this analysis, I write down a series of questions and answer them one-by-one. Scroll down to see the questions ‚¨áÔ∏è

This project was fun for me because I worked with a friend who knows a lot more about film than I do. He studied film in school and provided a lot of insight into the post here. From picking interesting questions to ask to interpretting trends and patterns in the data where I was confused, his help was valuable!

## Previous Studies

I started this analysis by looking at what others had done with movie sequels. I found loads of data movie analyses, but few about movie sequels. Here are a few interesting links I found specifically about sequels: 

- I found a [kaggle project](https://www.kaggle.com/code/orimeidler/are-sequel-movies-really-worse) looking at this question, and I followed a similar data preparation process (without using French Wikipedia). He takes an indepth look at the question.. Are movie sequels less quality?
- [This one](https://stephenfollows.com/hollywood-sequels-by-the-numbers/) gives a good overview of some of the assumptions that go into this type of analysis. For example, "how is a series defined?" and "What do we do with series that have changed significantly over time?"  
- [This one](https://www.kdnuggets.com/2015/10/movie-sequels-better-data-science.html#comments) looks interesting, but several of the figures wouldn't render on my device which referenced the company silk.co. I am skeptical that this website/company still exists.  

## Data

For the data, I used [a list created on IMDB](https://www.imdb.com/list/ls003495084/) containing around 1200 movies and sequels. It is not an exhaustive list, but it covers a lot of ground. Unfortunately, this list was missing a few things I wanted such as the movie's revenue, budget, language, production company, and other variables. I joined these in via the [TMBD API](https://developer.themoviedb.org/docs/getting-started). The data is available for download on the link to the side.

In the first chart, I also join in a non-commercial dataset from IMDB which can be accessed [here](https://datasets.imdbws.com).

:::{.callout-warning}
The data from TMDB is community based - meaning people self-report the revenue and some of the other data. Unfortunately, this means that there may be errors at times in the data. There are state-of-the-art data and APIs available, but only through paywalls and I'm not paying üòÇ
:::

## Definition

In this blog post, I primarily look at the first movie in a series and its immediate sequel. There's certainly a lot more to be explored in the dataset, but I choose to filter this way because of its simplicity. I won't have to worry about sparcity as sequel number increases and important differences between case1, original and sequel #1, vs case2, sequel #X and sequel #X+1.

## Questions

```{python}
# | include: false
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px
import plotly.graph_objects as go
import statsmodels.api as sm
import scipy.stats as stats
from statsmodels.stats.outliers_influence import variance_inflation_factor
from IPython.display import HTML

#import my data
data = pd.read_excel("./cleaned_data_w_rev.xlsx")

#create a variable for popular production companies
data.loc[data.production_company.isna(),"production_company"] = ""
data['warner_bros'] = data.production_company.str.contains("Warner Bros.").astype("int")
data['fox'] = data.production_company.str.contains("20th Century Fox").astype("int")
data['mgm'] = data.production_company.str.contains("Metro-Goldwyn-Mayer").astype("int")
data['universal'] = data.production_company.str.contains("Universal Pictures").astype("int")
data['disney'] = data.production_company.str.contains("Disney").astype("int")
data['paramount'] = data.production_company.str.contains("Paramount").astype("int")
data['marvel'] = data.production_company.str.contains("Marvel").astype("int")

chart_later = data[['warner_bros', 'fox', 'mgm', 'universal', 'disney', 'paramount']].sum(axis=0).sort_values(ascending=False)

data['prod_i'] = np.where(data['warner_bros'] == 1, 'Warner',
  np.where(data['fox'] == 1, 'Fox',
    np.where(data['universal'] == 1,'Universal',
      np.where(data['disney'] == 1, "Disney", "Other"))))

```

#### Are There More Sequels Over Time?

:::{.callout-warning}
Upon manual inspection of the data, I noticed that the list did not include a lot of movie sequels after 2010 eventhough some exist. For example, my data includes the first 5 Tinker Bell Movies up until 2012, but does not include movies 6-8. [Yes, there are 8 Tinker Bell moviesüòÇ](https://www.imdb.com/list/ls063298470/). So, I would interpret the decrease in sequels after 2012 with caution.
:::

```{python}
# | echo: false
# | include: false
# filter to sequels only
to_join = pd.read_csv("./to_join.csv")
sequels = data.query("sequel_num >= 2")

# Scatter plot X: Time, Y: Count
y = sequels.groupby("Year").agg('count')['Title'].to_list()
x = sequels.groupby("Year").agg('count')['Title'].index.to_list()

#Joining in all movies
sequels = pd.DataFrame({"Num_sequels":y,"Year":x})
sequels = sequels.merge(to_join, on="Year", how="left")
y2 = sequels["Movie_num"]

fig, ax1 = plt.subplots()

color = '#342bbb'
ax1.set_xlabel('Year')
ax1.set_ylabel('Sequel Count', color=color)
ax1.plot(x, y, color=color)
ax1.tick_params(axis='y', labelcolor=color)

ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis

color = '#BB3E18'
ax2.set_ylabel('Movie Count', color=color)  # we already handled the x-label with ax1
ax2.plot(x, y2, color=color)
ax2.tick_params(axis='y', labelcolor=color)

fig.tight_layout()  # otherwise the right y-label is slightly clipped
plt.annotate(
    "Source: IMBD/TMBD",
    xy=(0.7, -0.17),
    xycoords="axes fraction",
)

plt.title("Sequels Spiked Around 2010")
plt.savefig("./fig1.png",bbox_inches='tight')
```

![](./fig1.png)

**Main Takeaway:** It seems there was a spike in sequels after the year 2000. And, the spike in sequels may have come a little bit before the spike in movies, but, generally, sequel production has followed the movie production trend overall and **increased over time**.

#### Do Sequels Make More Than The Original?

:::{.callout-note}
I noticed that several movie revenues were missing, so I went through each missing value and looked up the revenue [here](https://www.the-numbers.com) which is the recommended resource for TMDB contributors (read more in the [TMDB Bible](https://www.themoviedb.org/bible/movie/59f3b16d9251414f20000001#59f73b759251416e71000007)). Originally, there were some significant movies that showed $0 such as Avatar (the blue people version), one of the best performing films ever. I added in all the latest numbers in the data that can be downloaded on the right.

These number *are* inflation adjusted using the CPI.
:::


```{python}
# | echo: false
# | panel: fill
fig2_data = data.query("sequel_num in [1,2]") \
  .assign(log_of_revenue = lambda x:np.log(x.adjusted_rev+1))

def get_rev_1(data_part):
  tmp = data_part.sort_values("sequel_num").reset_index(drop=True)
  return tmp.loc[0,"adjusted_rev"]

def get_rev_2(data_part):
  tmp = data_part.sort_values("sequel_num").reset_index(drop=True)
  return tmp.loc[1,"adjusted_rev"]

def get_title(data_part):
  tmp = data_part.sort_values("sequel_num").reset_index(drop=True)
  return tmp.loc[0,"Title"] + " Series"

def get_prod(data_part):
  tmp = data_part.sort_values("sequel_num").reset_index(drop=True)
  return tmp.loc[0,"prod_i"]

x = data.query("sequel_num in [1,2]") \
  .groupby("sequel_group") \
  .apply(get_rev_1)

y = data.query("sequel_num in [1,2]") \
  .groupby("sequel_group") \
  .apply(get_rev_2)

title = data.query("sequel_num in [1,2]") \
  .groupby("sequel_group") \
  .apply(get_title)

prod = data.query("sequel_num in [1,2]") \
  .groupby("sequel_group") \
  .apply(get_prod)

plot_data = pd.DataFrame(
  {
    'original_revenue':x,
    'sequel_revenue':y,
    'series':title,
    'production_company':prod
  }
)

plot_data = plot_data.assign(
  original_revenue_log = lambda z:np.log(z.original_revenue+1),
  sequel_revenue_log = lambda z:np.log(z.sequel_revenue+1)
)

fig = px.scatter(plot_data, x="original_revenue", y="sequel_revenue", color="production_company", hover_name="series", hover_data=[ "original_revenue", 'sequel_revenue','production_company'])
fig.add_trace(go.Scatter(x=[0, 5_000_000_000], y=[0, 5_000_000_000], mode='lines', name='Profit Line'))
fig.update_traces(line_color='black')
fig.update_layout(
  title='Original Film VS. First Sequel',
  xaxis_title="First Film's Revenue (infl. adj.)",
  yaxis_title="Second Film's Revenue (infl. adj.)",
  yaxis_range=[0, 5_000_000_000],
  xaxis_range=[0, 5_000_000_000]
)
fig.add_annotation(
  text="Source: IMDB/TMDB",
  xref="paper", yref="paper",
  x=3, y=-0.2, showarrow=False)
fig.update_yaxes(nticks=5)

# Create the button
button = dict(
  type="buttons",
  direction="right",
  active=0,
  x=1.25,
  y=1.15,
  buttons = list([
    dict(label='Unlogged Axes', method='relayout', args=[{'yaxis.type':'linear', 'xaxis.type':'linear'}]),
    dict(label='Logged Axes', method='relayout', args=[{'yaxis.type':'log', 'xaxis.type':'log'}])
  ])
)

# Add the button to the layout
fig.update_layout(updatemenus=[button])

fig.show()
```
<br>

**This chart is interactive.** Click or press the different points which each represent a different series. Use the toolbar to zoom in and out on certain parts of this graph for further exploration.

Notice how more dots are below the line then above the line, this indicates that the originals typically perform better than the sequels. But, lets look at a few other charts to confirm our thinking.

:::{.callout-tip}
You may be surprised to see Bambi as the highest original film box office in my sequel dataset. But, remember, this film was first released in 1942 [with a worldwide box office of $268 Million](https://www.the-numbers.com/custom-search?searchterm=bambi). In today's dollars, this is valued a lot higher!
:::

```{python}
# | echo: false
# | include: false

def seq_diff(data_part):
  tmp = data_part.sort_values("sequel_num").reset_index(drop=True)
  val = tmp.loc[0,"adjusted_rev"] - tmp.loc[1,"adjusted_rev"]
  within_5 = np.multiply(np.divide(tmp.loc[0,"adjusted_rev"],100),5)
  if val > within_5:
    r_val = "original made more"
  elif val < -within_5:
    r_val = "sequel made more"
  else:
    r_val = "about the same"
  return r_val

fig3_data = data.query("sequel_num in [1,2]") \
  .groupby("sequel_group") \
  .apply(seq_diff)

cat_type = pd.api.types.CategoricalDtype(categories=["sequel made more", "about the same", "original made more"], ordered=True)

fig3_data = fig3_data.astype(cat_type)

p = sns.histplot(x=fig3_data, stat="proportion", shrink=.8, color='#251e83')#'#688311',
plt.title("More Than 60% of the Time, The Original Made More \$\$")
plt.ylabel("Proportion")
plt.annotate(
    "Source: IMBD/TMBD",
    xy=(0.7, -0.17),
    xycoords="axes fraction",
)
plt.savefig("./fig2.png")
```

![](./fig2.png)

:::{.callout-tip}
Above, I define "About the same" when the revenue of the sequel is the same as the original within a 10% margin (+/- 5%)
:::

Looking at a simple crosstab breakout above, we see that the original movie is likely to make more money than the sequel more than 60% of the time.

```{python}
# | echo: false
# | include: false
fig2_data = data.query("sequel_num in [1,2]") \
  .assign(log_of_revenue = lambda x:np.log(x.adjusted_rev+1))

p = sns.histplot(data=fig2_data, x="log_of_revenue", hue="sequel_num", element="step", palette = ['#688311', '#251e83'])
sns.move_legend(p, "upper right", title='Movies', frameon=False)
plt.title("Bimodal Distrbution at \$0 and e^19 ‚âà \$180 Million")
plt.ylabel("Movie Count")
plt.xlabel("Log of Revenue")
plt.annotate(
    "Source: IMBD/TMBD",
    xy=(0.7, -0.17),
    xycoords="axes fraction",
)
plt.savefig("./fig3.png")
```

![](./fig3.png)

However, if you look at the distributions between the original and the sequel, they look quite similar. There is an exception though: sequels are much more likely to make zero dollars.

**Main Takeaway:** More than 60% of the time, the original outperforms the sequel. If the sequel makes revenue, the sequel may perform similarly to the original in revenue.

#### Are Sequels Rated Higher Than The Original?

```{python}
# | echo: false
# | include: false
fig_data = data.query("sequel_num in [1,2]") \
  .assign(log_of_revenue = lambda x:np.log(x.revenue+1))

p = sns.histplot(data=fig_data, x="IMDb Rating", hue="sequel_num", element="step", palette = ['#688311', '#251e83'])

og_med = fig_data.query("sequel_num == 1")["IMDb Rating"].median()

p.axvline(og_med, color='#688311', lw=4)

p.text(x=7.2, y=60, s=f'Original Median:\n{og_med}', color='#688311')

sql_med = fig_data.query("sequel_num == 2")["IMDb Rating"].median()

p.axvline(sql_med, color='#251e83', lw=4)

p.text(x=5.9, y=53, s=f'Sequel Median:\n{sql_med}', color='#251e83',
horizontalalignment = "right")

sns.move_legend(p, "upper left", title='Movies', frameon=False)
plt.title("On Average, Originals Have Higher Ratings")
plt.ylabel("Movie Count")
plt.xlabel("IMDB Score")
plt.annotate(
    "Source: IMBD/TMBD",
    xy=(0.7, -0.17),
    xycoords="axes fraction",
)
plt.savefig("./fig4.png")
```

![](./fig4.png)

The IMDB distributions for these are fairly gaussian bell-curve looking. As you can see, the original is on average rated higher with a median rating of 6.9 whereas the sequel is on averate rated lower with a median of 6.1.

We are just looking at the overall distributions here, but we can calculate the actual average difference in score which I do below.

```{python}
def imdb_diff(data_part):
  tmp = data_part.sort_values("sequel_num").reset_index(drop=True)
  return tmp.loc[0,"IMDb Rating"] - tmp.loc[1,"IMDb Rating"]

diff = data.query("sequel_num in [1,2]") \
  .groupby("sequel_group") \
  .apply(imdb_diff) \
  .mean()

diff = round(diff,2)

print(f"On average, the original is rated {diff} points higher than its sequel")
```

**Takeaway:** According to our dataset, IMDB Scores are about 0.8 points higher for original movies than for their immediate sequels.

#### Are Sequels More Popular Than The Original?

```{python}
# | echo: false
# | include: false
fig2_data = data.query("sequel_num in [1,2]") \
  .assign(log_of_popularity = lambda x:np.log(x.popularity+1))

p = sns.histplot(data=fig2_data, x="log_of_popularity", hue="sequel_num", element="step", palette = ['#688311', '#251e83'])
sns.move_legend(p, "upper right", title='Movies', frameon=False)
plt.title("Similar Popularity Scores; Originals Have Slight Edge")
plt.ylabel("Movie Count")
plt.xlabel("Log of Popularity")
plt.annotate(
    "Source: IMBD/TMBD",
    xy=(0.7, -0.17),
    xycoords="axes fraction",
)
plt.savefig("./fig5.png")
```

![](./fig5.png)

The TMDB popularity score is intended to be a "lifetime popularity score" for movies. It is created by putting together website traffic and human interaction with each movie on TMDB. You can read a more indepth discussion of this metric [here](https://developer.themoviedb.org/docs/popularity-and-trending).

**Takeaway:** According to TMDB's popularity metric, originals and sequels look similar in popularity with the originals perhaps having a slight edge.

I was supprised when this variable was shockingly right skewed. I assumed the creators would have normalized their score, so that is why I log transform here.

#### Do Sequels Typically Recieve Less Budget?

:::{.callout-note}
These number *are* inflation adjusted using the CPI.
:::

```{python}
# | echo: false
# | include: false
sequels12 = data.query("sequel_num in [1,2,3,4]")
x = sequels12.groupby('sequel_num')['adjusted_budget'].agg("mean").index.to_list()
y = sequels12.groupby('sequel_num')['adjusted_budget'].agg("mean").to_list()
p = sns.barplot(x=x,y=y, color="#342bbb")
plt.title("On Average, Sequels Seem to Get More Budget")
p.text(x=-0.19, y=52_000_000, s="n=410", color = "white")
p.text(x=0.8, y=57_000_000, s="n=410", color = "white")
p.text(x=1.8, y=60_000_000, s="n=189", color = "white")
p.text(x=2.85, y=68_000_000, s="n=77", color = "white")
plt.ylabel("Budget $")
plt.xlabel("Sequel Number")
plt.annotate(
    "Source: IMBD/TMBD",
    xy=(0.7, -0.17),
    xycoords="axes fraction",
)
plt.savefig("./fig6.png")
```

![](./fig6.png)

:::{.callout-tip}
For most the analysis, I use just the original and first sequel; however, for this chart and the next, we look include more sequels.
:::

**Takeaway:** Lower numbers of sequels are more common (you can see the N-size decrease as the sequel number increases), but the trend is clear; sequels on average recieve a higher budget.

#### Which Production Companies Make The Most Sequels?

```{python}
# | echo: false
# | include: false
fig, ax = plt.subplots()

y_pos = np.arange(len(chart_later.index))
ax.barh(y_pos, chart_later.values, align='center',color="#342bbb")
ax.set_yticks(y_pos, labels=chart_later.index)
ax.invert_yaxis()  # labels read top-to-bottom
ax.set_xlabel('Number of Sequels Made')
ax.set_title('Every Large Production Studio Makes Sequels')
plt.savefig("./fig7.png")
```

![](./fig7.png)

**Takeaway:** Of the companies listed, each one dips its fingers in the sequel game. But, according to our data, 20th Century Fox and Universal Studios have made the most sequels.

*Future note: It would be interesting to see the total number of movies each company has made to compare the proportion.*

#### What Predicts The Monetary Success of Sequels?

For this section, I created a statistical model to help answer the next few questions. The model is good measuring the independent impact of multiple variables inputted. This method will help us tease out more findings from out data.

It is important to keep in mind that this model is predicting the difference in revenue from original to sequel and the factors that influence this difference.

:::{.callout-note}
You can view my modeling steps and process in my downloadable python script.
:::

```{python}
# | echo: false
# | include: false

def prepare_data(data_part):
  tmp = data_part.sort_values("sequel_num").reset_index(drop=True)
  time_between = np.abs(tmp.loc[0,"Year"] - tmp.loc[1,"Year"])
  budget_diff = tmp.loc[1,"adjusted_budget"] - tmp.loc[0,"adjusted_budget"]
  same_director = int(tmp.loc[0,"Directors"] == tmp.loc[1,"Directors"])
  imdb_diff = tmp.loc[1,"IMDb Rating"] - tmp.loc[0,"IMDb Rating"]
  action = int('Action' in str(tmp.loc[1,"Genres"]))
  horror = int('Horror' in str(tmp.loc[1,"Genres"]))
  comedy = int('Comedy' in str(tmp.loc[1,"Genres"]))
  romance = int('Romance' in str(tmp.loc[1,"Genres"]))
  family = int('Family' in str(tmp.loc[1,"Genres"]))
  return_df = pd.DataFrame({
    'same_director': same_director,
    'time_between': time_between,
    'imdb_diff': imdb_diff,
    'action': action,
    'horror': horror,
    'comedy': comedy,
    'romance': romance,
    'family': family,
    'budget_diff': budget_diff,
    'warner_bros': tmp.loc[1,"warner_bros"],
    'fox': tmp.loc[1,"fox"],
    'disney': tmp.loc[1,"disney"],
    'warner_bros': tmp.loc[1,"warner_bros"],
    'universal': tmp.loc[1,"universal"],
    'marvel': tmp.loc[1,"marvel"],
    'y': tmp.loc[1,"adjusted_rev"] - tmp.loc[0,"adjusted_rev"]
  }, index = [0])
  return return_df

data_to_model = data.query("sequel_num in [1,2]") \
  .groupby("sequel_group") \
  .apply(prepare_data)

def rescale(col):
  if any(col.gt(1)) or any(col.lt(0)):
    ncol = col - col.mean()
    ncol = ncol/col.std()
  else:
    ncol = col
  return ncol

y = data_to_model.y.values
X = data_to_model.reset_index() \
  .drop(columns = ['sequel_group', 'level_1', 'y'])
X = sm.add_constant(X)

model = sm.OLS(y, X)
results = model.fit()

coef_table = results.summary2()
coef_table = coef_table.tables[1] \
  .assign(Significant = lambda x:x['P>|t|']<0.05) \
  .rename(columns = {'Coef.':'Coefficient'})

coef_table[['Coefficient', 'Significant']].to_html()


# ############
# # Checking Regression Assumptions #
# ############

# # 1. Plotting Residuals (Checking Linearity)
# fitted_values = results.fittedvalues
# residuals = results.resid
# plt.scatter(fitted_values, residuals)
# plt.axhline(y=0, color='r', linestyle='-')
# plt.xlabel("Fitted values")
# plt.ylabel("Residuals")
# plt.title("Residuals vs. Fitted")
# #plt.show()
# # Things look decent here other than a few outliers.

# # 2. Checking Influential Observations
# influence = results.get_influence()
# cooks_distance = influence.cooks_distance
# threshold = 1
# g_x = [x for x in range(len(cooks_distance[0]))]
# g_y = cooks_distance[0]
# text = [[i,x] for i,x in enumerate(g_y) if x>threshold]
# for pair in text:
#   plt.text(x=pair[0]+1, y=pair[1], s=str(pair[0]))
# plt.stem(g_x, g_y, markerfmt=",", use_line_collection=True)
# plt.axhline(y=threshold, color='r', linestyle='-')
# plt.title("Cook's Distance Plot")
# plt.xlabel("Observation Number")
# plt.ylabel("Cook's Distance")
# #plt.show()
# # Bambi is a very influential observation - Maybe remove?

# # 3. Residuals are Normally Distributed
# stats.probplot(residuals, dist="norm", plot=plt)
# plt.title("Normal Q-Q Plot")
# #plt.show()
# #Showing an S-Shape which is indivative of Heavy Tails
# #Using Robust Standard Errors

# # 4. Multi-colinearity
# vif = pd.DataFrame()
# vif["Variable"] = X.columns
# vif["VIF"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]
# #Everything looks good here.

# # Given the checks, I'm going to try:
# # 1. Remove the outlier - Bambi
# # 2. Transform the 'Budget_diff' and 'Y' using yeojohnson transformation

# # I took this function from here: \/
# # https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PowerTransformer.html
def yeojohnson_inv(X_trans, lambda_):
  if X_trans >= 0 and lambda_ == 0:
    X = np.exp(X_trans) - 1
  elif X_trans >= 0 and lambda_ != 0:
    X = (X_trans * lambda_ + 1) ** (1 / lambda_) - 1
  elif X_trans < 0 and lambda_ != 2:
    X = 1 - (-(2 - lambda_) * X_trans + 1) ** (1 / (2 - lambda_))
  elif X_trans < 0 and lambda_ == 2:
    X = 1 - np.exp(-X_trans)
  return X

data_to_model = data.query("sequel_num in [1,2]") \
  .groupby("sequel_group") \
  .apply(prepare_data)
data_to_model['budget_diff'], lambda_value_bd =  \
  stats.yeojohnson(data_to_model.budget_diff.values)
data_to_model['y'], lambda_value_y =  \
  stats.yeojohnson(data_to_model['y'])
X = data_to_model.reset_index(drop=True)
X = X.iloc[X.index.to_numpy().__ne__(94),:]
y = X.y.values
X = X.drop(columns = ['y'])
X = sm.add_constant(X)

model = sm.OLS(y, X)
results = model.fit()
robust_results = results.get_robustcov_results()

coef_table = robust_results.summary2()
coef_table = coef_table.tables[1] \
  .assign(Significant = lambda x:x['P>|t|']<0.05) \
  .rename(columns = {'Coef.':'Impact'})

coef_table['Impact'] = np.where(coef_table['Impact']>0, '+', '-')
```

```{python}
# | echo: false
coef_table = coef_table[['Impact', 'Significant']].iloc[1:,:]
coef_table = coef_table.rename(
  {'same_director':'Original & sequel have the same director',
  'time_between':'Time between original and sequel',
  'imdb_diff':'Sequel IMDB score minus original',
  'action':'Action movie',
  'horror':'Horror movie',
  'comedy':'Comedy movie',
  'romance':'Romance movie',
  'family':'Family movie',
  'budget_diff':'Sequel budget minus original',
  'warner_bros':'Warner Bros movie',
  'fox':'Fox movie',
  'disney':'Disney movie',
  'universal':'Universal movie',
  'marvel':'Marvel movie'}
)
HTML(coef_table.to_html(justify='center').replace('<td>', '<td align="center">'))
```

Here is a table showing us the impact of each variable (Impact) positive or negative and whether the model was able to statistically differentiate the effect from zero (Significant).

I will note a few things here, but a few of the findings in this table relate to future questions. So will leave those parts for those sections.

**Takeaway #1:** Having a higher quality movie (higher IMDB score) has a positive significant effect on the revenue of the sequel.

**Takeaway #2:** Some genres could perform better than others. We see a positive effect from sequels of action (Maybe that's why there are so many super hero movies ü§∑‚Äç‚ôÇÔ∏è). While these relationship are not statistically significant, our model's best guess for horror and action sequels is a positive effect and for family and romance sequels is a negative effect. Perhaps with more sequel data we could detect differences there.

**Takeaway #3:** None of the big production companies have a positive statistically significant impact on the revenue of a sequel when compared to the original.

#### How Does Timing Affect A Sequel's Success?

```{python}
# | include: false
rnge = np.array([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15])

X_varied = {k:[v for x in range(len(rnge))] for k,v in X.mean().to_dict().items()}
X_varied = pd.DataFrame(X_varied)

X_varied['time_between'] = rnge

predictions = robust_results.get_prediction(exog=X_varied)
predictions_summary = predictions.summary_frame(alpha=0.05)

upper = [yeojohnson_inv(x,lambda_value_y) for x in predictions_summary['mean_ci_upper']]
lower = [yeojohnson_inv(x,lambda_value_y) for x in predictions_summary['mean_ci_lower']]
mns = [yeojohnson_inv(x,lambda_value_y) for x in predictions_summary['mean']]

plt.fill_between(
  x=rnge,
  y1=upper,
  y2=lower,
  alpha=0.25
)
plt.plot(rnge, mns)
plt.title("Bigger Time Gap, Bigger Revenue Loss")
plt.ylabel("Predicted Revenue of Sequel - Original ($)")
plt.xlabel("Years Between Original & Sequel")
plt.savefig("./fig8.png")
```
![](./fig8.png)

**Takeaway:** The answer? It's not good. In fact, our model predicts that for each additional year of waiting, the sequel will lose $10 Million on average.

#### Do Sequels With More Budget Fair Better?

```{python}
# | include: false
rnge = stats.yeojohnson(np.array([-1_000_000,0,1_000_000]),lambda_value_bd)

X_varied = {k:[v for x in range(len(rnge))] for k,v in X.mean().to_dict().items()}
X_varied = pd.DataFrame(X_varied)

X_varied['budget_diff'] = rnge

predictions = robust_results.get_prediction(exog=X_varied)
predictions_summary = predictions.summary_frame(alpha=0.05)

upper = [yeojohnson_inv(x,lambda_value_y) for x in predictions_summary['mean_ci_upper']]
lower = [yeojohnson_inv(x,lambda_value_y) for x in predictions_summary['mean_ci_lower']]
mns = [yeojohnson_inv(x,lambda_value_y) for x in predictions_summary['mean']]

plt.fill_between(
  x=rnge,
  y1=upper,
  y2=lower,
  alpha=0.25
)
plt.plot(rnge, mns)
plt.title("Budget Difference? - No Impact")
plt.ylabel("Predicted Revenue of Sequel - Original ($)")
plt.xlabel("Budget Sequel - Original ($)")
plt.savefig("./fig9.png")
```
![](./fig9.png)

**Takeaway:** As you can see, the line is pretty flat meaning budget does not have a meaningful impact in our model. Though our model's best guess is budget having a positive impact on sequel revenue.

#### Are Sequels Who Keep The Same Director More Or Less Successful?

```{python}
# | include: false
rnge = np.array([0,1])

X_varied = {k:[v for x in range(len(rnge))] for k,v in X.mean().to_dict().items()}
X_varied = pd.DataFrame(X_varied)

X_varied['same_director'] = rnge

predictions = robust_results.get_prediction(exog=X_varied)
predictions_summary = predictions.summary_frame(alpha=0.05)

upper = [yeojohnson_inv(x,lambda_value_y) for x in predictions_summary['mean_ci_upper']]
lower = [yeojohnson_inv(x,lambda_value_y) for x in predictions_summary['mean_ci_lower']]
mns = [yeojohnson_inv(x,lambda_value_y) for x in predictions_summary['mean']]

plt.fill_between(
  x=rnge,
  y1=upper,
  y2=lower,
  alpha=0.25
)
plt.plot(rnge, mns)
plt.title("Same Director? - No Impact")
plt.ylabel("Predicted Revenue of Sequel - Original ($)")
plt.xlabel("0=Diff Director;1=Same Director")
plt.savefig("./fig10.png")
```
![](./fig10.png)

**Takeaway:** Our model doesn't find a statistically significant relationship between keeping directors. Interestingly, our model's best guess is a negative impact on sequel revenue when a director is kept.

## Notes for Future Study

I have a few notes here in case any data folks are interested in looking into things further...

- For my analysis, I primarly looked at the original and the first sequel. However, my dataset contains a lot more than that! It would be interesting continuing this analysis looking at how adding more sequels after the first affects things like popularity, IMDB score, and revenue.

- I mainly focused on revenue as my primary dependent variable. Perhaps exploring IMDB score and popularity would also be interesting dependent variables.

- When I was finishing up the analysis I found that TMDB has a part of its API where you can access [collections which are functionally movie series](https://www.themoviedb.org/bible/collection#5a0b1dee9251416561000009). For researchers interested in a more expansive dataset than I compiled, this may be a good place to start.

- It would be interesting to zoom in on a particular subset. For example, maybe a specific production company has meaningful differences to explore or a specific genre.

## Conclusion

Thanks for reading. Feel free to use my code and dataset freely. If you end up using anything, shoot me a message. I'd love to see other analyses and ideas. For technical questions, check the [python script](/files/sequel_analysis.py) and [download the data](/files/cleaned_data_w_rev.xlsx). I go in detail checking and validating the regression model used in this post.

If you enjoyed the read or have any questions about the analysis or other ideas, drop a comment below!
